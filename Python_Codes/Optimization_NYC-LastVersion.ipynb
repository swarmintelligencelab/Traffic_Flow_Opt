{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528c1956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from shapely import wkt\n",
    "from shapely.geometry import LineString,Point\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3dd22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Geometry of Upper West Manhattan entre\n",
    "from shapely import geometry\n",
    "\n",
    "p1 = geometry.Point(-73.97677315899479, 40.7745052767513)\n",
    "p2 = geometry.Point(-73.98835952571092, 40.77956196499991)\n",
    "p3 = geometry.Point(-73.98184403696767, 40.78666077169789)\n",
    "p4 = geometry.Point(-73.97111445307536, 40.78212846853962)\n",
    "pointList = [p1, p2, p3, p4, p1]\n",
    "p = geometry.Polygon([[p.x, p.y] for p in pointList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = ox.graph_from_polygon(p, network_type=\"drive\")\n",
    "ox.routing.add_edge_speeds(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27afb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of edges and nodes\n",
    "list_nodes = list(G.nodes)\n",
    "list_edges = list(G.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characteristic length of vehicle\n",
    "l_caract = 4 # m/vehicle\n",
    "\n",
    "for ed in list_edges:\n",
    "    \n",
    "    if 'lanes' in G.edges[ed]:\n",
    "        G.edges[ed]['lanes'] = float(G.edges[ed]['lanes'][0])\n",
    "    else:\n",
    "        G.edges[ed]['lanes'] = 1\n",
    "\n",
    "    G.edges[ed]['speed_mps'] = G.edges[ed]['speed_kph']/3.6\n",
    "    G.edges[ed]['capacity'] = G.edges[ed]['speed_mps']/G.edges[ed]['length']\n",
    "    G.edges[ed]['xMax'] = G.edges[ed]['length']*G.edges[ed]['lanes']/l_caract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92d25a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we need to organize the map and conncet missing points\n",
    "nodes,streets = ox.graph_to_gdfs(G)\n",
    "streets.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbd046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Dual Graph\n",
    "H = nx.line_graph(G)\n",
    "H.add_nodes_from((node, G.edges[node]) for node in H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1426b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the position of the dual graph's nodes in the middle of the street\n",
    "edges = G.edges()\n",
    "nodes_position = {}\n",
    "c = 0\n",
    "for node in H:\n",
    "    c+=1\n",
    "    u, v, key = node  # Extract primal edge (u, v, key)\n",
    "    \n",
    "    # Get the data for the edge in the primal graph\n",
    "    edge_data = G.get_edge_data(u, v, key)    \n",
    "    \n",
    "    # Check if the edge has a 'geometry' attribute\n",
    "    if 'geometry' in edge_data:\n",
    "        geom = edge_data['geometry']\n",
    "    else:\n",
    "        # If no geometry exists, create a simple LineString between u and v\n",
    "        geom = LineString([(G.nodes[u]['x'], G.nodes[u]['y']), (G.nodes[v]['x'], G.nodes[v]['y'])])        \n",
    "\n",
    "    bb = geom.centroid\n",
    "    x = bb.xy[0][0]\n",
    "    y = bb.xy[1][0]\n",
    "    nodes_position[node]=(x,y)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f684f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the edges of the dual graph and assign the weight and length\n",
    "edges = H.edges\n",
    "\n",
    "for ed in edges:\n",
    "    H.edges[ed]['weight'] = H.nodes[ed[0]]['capacity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75876c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Geopandas object from the graph together with the bounding box\n",
    "nodes,streets = ox.graph_to_gdfs(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eb7a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data of ATC and get colum names\n",
    "import numpy as np\n",
    "trafficVol = pd.read_csv(\"ATC_Manhattan.csv\")\n",
    "column_name = trafficVol.columns\n",
    "column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6425da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Segments IDs\n",
    "unique_segments = trafficVol.SegmentID.unique()\n",
    "# I will work with a numpy matrix instead of Pandas for simplicity\n",
    "matValues = trafficVol.iloc[:,0:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate segments that has less than nSample points:\n",
    "nSample = 10\n",
    "for seg in unique_segments:\n",
    "    \n",
    "    ids = np.argwhere(matValues[:,8]==seg)         \n",
    "    len_data = len(ids)\n",
    "    if(len_data<nSample):              \n",
    "        matValues = np.delete(matValues,ids,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5e9546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create again the Data Frame with eliminated rows\n",
    "trafficVol = pd.DataFrame(matValues,columns=column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d255f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract location of ATC\n",
    "trafficVol[\"WktGeom\"] = gpd.GeoSeries.from_wkt(trafficVol[\"WktGeom\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e74b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(trafficVol, geometry=\"WktGeom\",crs='2263')\n",
    "gdf = gdf.to_crs(4326)\n",
    "gdf = gdf.clip(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc0af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate spurious edges and fix some issues with two way roads\n",
    "list_eliminate = [37175, 146736]\n",
    "for seg in list_eliminate:\n",
    "    idDrop = gdf[gdf[\"SegmentID\"]==seg].index\n",
    "    gdf = gdf.drop(idDrop)\n",
    "    \n",
    "mapping = {(164893,\"WB\"):(1061531597,42443332,0),\n",
    "  (34502,\"SB\"):(42437384,42443332,0),\n",
    "  (34488,\"NB\"):(42442422,9177424867,0),\n",
    "  (34498,\"SB\"):(42428634,1061531448,0),\n",
    "  (37081,\"NB\"):(42435272,42435275,0),\n",
    "  (34399,\"EB\"):(595245843,42424032,0),\n",
    "  (34399,\"WB\"):(42424032,595245843,0), # Este           \n",
    "  (34405,\"EB\"):(42424032,42431004,0),\n",
    "  (34405,\"WB\"):(42431004,42424032,0),\n",
    "  (34505,\"WB\"):(42428634,42431004,0),\n",
    "  (37082,\"WB\"):(42443336,6207264908,0),\n",
    "  (37088,\"WB\"):(42435275,42443336,0),\n",
    "  (37088,\"EB\"):(42443336,42435275,0),# Este\n",
    "  (37089,\"SB\"):(42432556,42435275,0),\n",
    "  (37083,\"SB\"):(42432558,42443336,0),\n",
    "  (34512,\"NB\"):(42432564,42442445,0),\n",
    "  (37095,\"SB\"):(42428061,42438859,0),\n",
    "  (34536,\"NB\"):(42438862,42428063,0),\n",
    "  (34526,\"NB\"):(42428068,42431019,0),\n",
    "  (34542,\"EB\"):(42422592,42431019,0)}    \n",
    "\n",
    "mapKeys = list(mapping.keys())\n",
    "mapVals = list(mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfddec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add the two way segments to the GeoPandas DataFrame\n",
    "gdf.insert(9,\"From_OSMID\",1)\n",
    "gdf.insert(10,\"To_OSMID\",1)\n",
    "gdf.insert(11,\"Adj_Mat_id\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51cb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract again the numpy version to better work with it\n",
    "matrix = gdf.iloc[:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170a76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mapKeys)):\n",
    "    ids = np.argwhere((matrix[:,8]==mapKeys[i][0]) & (matrix[:,-1] == mapKeys[i][1])) \n",
    "    matrix[ids,9] = mapVals[i][0]\n",
    "    matrix[ids,10] = mapVals[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6ba789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Node List with the added Edges\n",
    "H_node_list = list(H.nodes())\n",
    "H_node_list_2 = np.array(H_node_list)\n",
    "H_node_list_2 = H_node_list_2[:,0:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c342bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(matrix)):\n",
    "    nodeId = np.where((H_node_list_2 == matrix[i,9:11]).all(axis=1))\n",
    "    matrix[i,11] = nodeId[0][0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b4e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = gdf.columns\n",
    "gdf2 = pd.DataFrame(matrix,columns=column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29376df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the data of each node\n",
    "NodeData = pd.DataFrame.from_dict(H.nodes, orient='index')\n",
    "NodeData = NodeData.reset_index()\n",
    "NodeData = NodeData.rename(columns={\"level_0\": \"from_OSMID\", \"level_1\": \"to_OSMID\", \"level_2\":\"Adj_Id\"})\n",
    "NodeData[\"Adj_Id\"]=range(len(NodeData))\n",
    "W = nx.adjacency_matrix(H,weight='weight').todense()\n",
    " \n",
    "xMax = NodeData[\"xMax\"]\n",
    "\n",
    "numNodes = H.number_of_nodes()\n",
    "\n",
    "def Laplacian_Matrix(W):\n",
    "    return np.diag(np.sum(W, axis = 1)) - W.T\n",
    "\n",
    "Lout = Laplacian_Matrix(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3673c7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_W = pd.DataFrame(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f494081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Calibrated parameters a and b\n",
    "bMatrix = np.loadtxt('parameters_b.csv',skiprows=1,delimiter=',')\n",
    "aMatrix = np.loadtxt('parameters_a.csv',skiprows=1,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ca60f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aMatrix = aMatrix[:,1:]\n",
    "bMatrix = bMatrix[:,1:]\n",
    "xMax = np.array(xMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d710adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate order parameter as a function of b in the Manhattan Matrix at two different times of the day\n",
    "\n",
    "hora = [0,12]\n",
    "\n",
    "kVector = np.linspace(1,50,100)\n",
    "orderParameter1 = np.zeros([len(kVector),2])\n",
    "\n",
    "\n",
    "for uu in range(len(hora)):\n",
    "\n",
    "    hr = hora[uu]\n",
    "    alpha = aMatrix[:,hr]\n",
    "    bb = bMatrix[:,hr]\n",
    "\n",
    "    h = 1e-2\n",
    "\n",
    "    tSimul = np.arange(0,30,h) # \n",
    "    AlphaMatrix = np.diag(alpha)\n",
    "\n",
    "    j = 0\n",
    "\n",
    "    Aalpha = -(Lout+AlphaMatrix)\n",
    "\n",
    "    for k in kVector:        \n",
    "\n",
    "        bu = k*bb\n",
    "        xStar = -np.linalg.inv(Aalpha)@bu\n",
    "        xJam = np.linalg.inv(AlphaMatrix)@bu \n",
    "\n",
    "        x = np.zeros((len(tSimul),numNodes))\n",
    "\n",
    "        for i in range(0,len(tSimul)-1):\n",
    "\n",
    "            nodes_occupied = np.argwhere(x[i,:]>xMax)\n",
    "            Woccupied = np.copy(W)\n",
    "            Woccupied[:,nodes_occupied] = 0 \n",
    "            LoutOccupied = Laplacian_Matrix(Woccupied)\n",
    "            x[i+1,:] = x[i,:] + h*(-(LoutOccupied+AlphaMatrix)@x[i,:]+bu)\n",
    "\n",
    "\n",
    "        xFinal = np.mean(x[-500:,:],axis=0)    \n",
    "        orderParameter1[j,uu]=np.linalg.norm(xFinal-xStar)/np.linalg.norm(xStar-xJam)\n",
    "\n",
    "        print(k,orderParameter1[j,uu])\n",
    "\n",
    "        j+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22dc5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization of the network\n",
    "from scipy.optimize import minimize\n",
    "from scipy.sparse import csr_array,csc_array,diags_array\n",
    "from scipy.sparse.linalg import inv\n",
    "\n",
    "# This is Eq. 32\n",
    "def minim_func(dw,indices,A0,b,numNodes,xMax):            \n",
    "    DeltaW = csr_array((dw,indices),shape=(numNodes,numNodes)).todense()    \n",
    "    AW = -Laplacian_Matrix(DeltaW)    \n",
    "    Ahat = AW+A0\n",
    "    xEq = -np.linalg.inv(Ahat)@b\n",
    "        \n",
    "    return np.max(xEq-xMax)\n",
    "\n",
    "# This is the gradient which speeds up computaitons\n",
    "def grad_func(dw,indices,A0,b,numNodes,xMax):\n",
    "    grad_vector = np.zeros(len(dw))    \n",
    "    DeltaW = csr_array((dw,indices),shape=(numNodes,numNodes)).todense()\n",
    "    AW = -Laplacian_Matrix(DeltaW)    \n",
    "    Ahat = AW+A0\n",
    "    AhatInv = np.linalg.inv(Ahat)   \n",
    "    xEq = -AhatInv@b \n",
    "    \n",
    "    iMax = np.argmax(xEq-xMax)\n",
    "    \n",
    "    for q in range(len(dw)):\n",
    "        i = indices[0][q]\n",
    "        j = indices[1][q]        \n",
    "        dAHat_dwij = np.zeros((numNodes,numNodes))\n",
    "        dAHat_dwij[j,i] = 1\n",
    "        dAHat_dwij[i,i] = -1\n",
    "        aux = AhatInv@dAHat_dwij@AhatInv\n",
    "        \n",
    "        grad_vector[q] = (aux@b)[iMax] \n",
    "            \n",
    "    return grad_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9fc643",
   "metadata": {},
   "outputs": [],
   "source": [
    "horaVector = range(4,24)\n",
    "\n",
    "# Identify intervention graph\n",
    "indices = W.nonzero()\n",
    "# Laplacian Matrix\n",
    "Lout = Laplacian_Matrix(W)\n",
    "\n",
    "# Optimization Loop as in previous script\n",
    "for uu in range(len(horaVector)):\n",
    "    hora = horaVector[uu]\n",
    "\n",
    "    b = bMatrix[:,hora]\n",
    "    alpha = aMatrix[:,hora]\n",
    "    AlphaMatrix = np.diag(alpha)\n",
    "    Aalpha = -(Lout+AlphaMatrix)\n",
    "\n",
    "    A0 = -(Lout+AlphaMatrix)\n",
    "\n",
    "    n = len(indices[0])\n",
    "\n",
    "    numIter = 4\n",
    "\n",
    "    wTot_Vec = np.linspace(25,50,2)\n",
    "\n",
    "    bestXGrad = np.zeros((len(wTot_Vec),numIter))\n",
    "    bestSolution = np.zeros((len(wTot_Vec),n))\n",
    "    lastBest = 1e6*np.ones(len(wTot_Vec))\n",
    "\n",
    "    for outLoop in range(numIter):    \n",
    "        for k in range(len(wTot_Vec)):\n",
    "\n",
    "            dw0 = np.random.rand(n,)\n",
    "\n",
    "            w_tot = wTot_Vec[k]        \n",
    "            print('hora = ',hora,' iter = ',outLoop,' w_tot = ',w_tot)\n",
    "\n",
    "            cons = ({'type': 'eq', 'fun': lambda x:  w_tot-np.sum(x)})\n",
    "            bounds = [(0, None) for i in range(n)]\n",
    "\n",
    "            dw0 /= np.sum(dw0)\n",
    "            dw0 *= w_tot\n",
    "\n",
    "            # SLSQP \n",
    "            resultGrad = minimize(minim_func, x0=dw0, constraints=cons,jac=grad_func, bounds=bounds,\n",
    "                options={\"maxiter\" : 500}, method='SLSQP', args=(indices,A0,b,numNodes,xMax))\n",
    "\n",
    "            # Optimization result\n",
    "            dw0Grad = resultGrad.x\n",
    "\n",
    "            # Reconstruct intervention graph \n",
    "            DeltaW = csr_array((dw0Grad,indices),shape=(numNodes,numNodes)).todense()  \n",
    "            AW = -Laplacian_Matrix(DeltaW)\n",
    "            Ahat = AW+A0\n",
    "            # New equilibrium with intervention\n",
    "            x1Grad = -np.linalg.inv(Ahat)@b\n",
    "            bestXGrad[k,outLoop] = np.max(x1Grad-xMax)\n",
    "\n",
    "            # Save best result across iterations\n",
    "            if(np.max(x1Grad-xMax)<lastBest[k]):\n",
    "                bestSolution[k,:]=dw0Grad\n",
    "                lastBest[k]=np.max(x1Grad-xMax)\n",
    "\n",
    "    # Saves info to file for further use. Uncomment to execute next part\n",
    "    #filename = 'hora' + str(hora) + 'bestSolution_grad.txt'\n",
    "    #np.savetxt(filename,bestSolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1e8a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the best solution possible at 25 amount of resoruces check how the ciritcal \n",
    "# k shifts at different times of the day. It uses the saved files from the previous cell\n",
    "\n",
    "indices = W.nonzero()\n",
    "Lout = Laplacian_Matrix(W)\n",
    "\n",
    "horaVector = range(24)\n",
    "\n",
    "kSol_Interv = np.zeros(24)\n",
    "kini = 9\n",
    "\n",
    "for hr in horaVector:\n",
    "    filename = 'hora' + str(hr) + 'bestSolution_grad.txt'\n",
    "    dw25,dw50 = np.loadtxt(filename)     \n",
    "    \n",
    "    # Reconstruct intervention graph\n",
    "    DeltaW = csr_array((dw25,indices),shape=(numNodes,numNodes)).todense()  \n",
    "    AW = -Laplacian_Matrix(DeltaW)    \n",
    "    \n",
    "    b = bMatrix[:,hr]\n",
    "    alpha = aMatrix[:,hr]\n",
    "    AlphaMatrix = np.diag(alpha)\n",
    "    A0 = -(Lout+AlphaMatrix)    \n",
    "    \n",
    "    Ahat = AW+A0\n",
    "    \n",
    "    # Critical k where transition occurs\n",
    "    kSol_Interv[hr] = fsolve(equation1,kini,args=(xMax,Ahat,b,numNodes))\n",
    "    kini = kSol_Interv[hr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2317aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Figure 7\n",
    "\n",
    "from scipy.sparse import csr_array,csc_array,diags_array\n",
    "\n",
    "# Add required hour of the day to see the best intervention\n",
    "horas = [0,12]\n",
    "\n",
    "fig, axs = plt.subplots(2,2,dpi=300)\n",
    "\n",
    "axs[1,0].plot(hour_vector,kSol,'-o')\n",
    "axs[1,0].plot(hour_vector,kSol_Interv,'-o')\n",
    "axs[1,0].set_xlabel(r'Hour')\n",
    "axs[1,0].set_ylabel(r'$k_c$')\n",
    "axs[1,0].legend(['Original','Intervention'])\n",
    "\n",
    "\n",
    "axs[0,0].plot(kVector,orderParameter0,'o',label='00:00')\n",
    "axs[0,0].plot(kVector,orderParameter12,'o',label='12:00')\n",
    "axs[0,0].set_xlabel(r'$k$')\n",
    "axs[0,0].set_ylabel(r'$\\rho_\\infty$')\n",
    "axs[0,0].set_xlim(1,20)\n",
    "axs[0,0].set_ylim(0,0.4)\n",
    "axs[0,0].legend()\n",
    "\n",
    "indices = W.nonzero()\n",
    "\n",
    "\n",
    "for counter in range(len(horas)):\n",
    "\n",
    "    hr = horas[counter]\n",
    "\n",
    "    filename = 'hora' + str(hr) + 'bestSolution_grad.txt'\n",
    "    dw25,dw50 = np.loadtxt(filename) \n",
    "\n",
    "    DeltaW = csr_array((dw50,indices),shape=(numNodes,numNodes)).todense()  \n",
    "\n",
    "    # Relative change of the intervention graph with respect to the original weight\n",
    "    maskedW = np.zeros_like(DeltaW)\n",
    "    for i in range(len(DeltaW)):\n",
    "        for j in range(len(DeltaW)):\n",
    "            if(W[i,j]>0):\n",
    "                maskedW[i,j] = DeltaW[i,j]/W[i,j]\n",
    "\n",
    "    H3 = nx.from_numpy_array(DeltaW/20,create_using=nx.DiGraph)\n",
    "    widths3 = nx.get_edge_attributes(H3, 'weight')\n",
    "\n",
    "    edge_dictionary = nx.get_edge_attributes(H3, 'weight')\n",
    "    edge_weight = np.array(list(edge_dictionary.values()))\n",
    "    idxEdges = np.where(edge_weight>1e-5)\n",
    "    edgeWidthFinal = tuple(edge_weight[idxEdges])\n",
    "\n",
    "\n",
    "    edge_dictionary2 = nx.get_edge_attributes(H, 'weight')\n",
    "    edge_keys = list(edge_dictionary2.keys())\n",
    "    aaa = np.array(list(edge_dictionary2.keys()),dtype=object)\n",
    "    edgeListFinal = tuple(map(tuple, aaa[idxEdges]))\n",
    "\n",
    "\n",
    "    streets.plot(ax=axs[counter,1],linewidth=0.5)\n",
    "\n",
    "    nx.draw_networkx_edges(H,pos=nodes_position,node_size=2,\n",
    "                           edgelist=edgeListFinal,\n",
    "                           width=edgeWidthFinal,\n",
    "                           edge_color='red',\n",
    "                           arrowsize=2,connectionstyle=\"arc3,rad=0.1\",ax=axs[counter,1])\n",
    "\n",
    "    axs[counter,1].axis('off')\n",
    "    axs[counter,1].set_title(str(hr)+':00')\n",
    "\n",
    "    \n",
    "resolution_value = 300\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
